{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4d9206-821a-4e2b-92f0-0382bc90ff83",
   "metadata": {},
   "source": [
    "# step 0: Load required libraries and dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b96de-efc5-41b0-a589-6692c65b8b8b",
   "metadata": {},
   "source": [
    "# Step 1: Load data and model forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c14a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD Forecasts for comparisons.\n",
    "actuals_week = pl.from_pandas( pd.read_csv( \"./california-cases-per-week.csv\" ));\n",
    "actuals_day = pl.from_pandas( pd.read_csv( \"./california-cases-per-day.csv\" , names=[\"date\", \"count\"] ));\n",
    "competitors = pl.from_pandas( pd.read_csv( \"./forecasts_covid.csv\"));\n",
    "# Now pull in all the humpty forecasts\n",
    "# (please note these can be generated using the script '10_build_humpty_baseline.sh' located in the directory 'published_results'\n",
    "Hbaseline = \"humpty_baseline\"\n",
    "Hbasefiles = glob.glob( Hbaseline + \"/fore2*[0-9].csv\" ) ;\n",
    "humpty = { f[(f.find(\"fore\")+4):f.find( \".csv\" )]:pl.from_pandas( pd.read_csv( f ) ) for f in Hbasefiles }\n",
    "Hbasefiles_cum = glob.glob( Hbaseline + \"/fore2*[0-9]CUM.csv\" ); \n",
    "humpty_cum = { f[(f.find(\"fore\")+4):f.find(\"CUM.csv\")]:pl.from_pandas( pd.read_csv( f )) for f in Hbasefiles_cum }\n",
    "#x1 = pl.from_pandas( pd.read_csv( \"../data/humpty_day_forecasts.csv\" ));\n",
    "actuals_day=actuals_day.with_columns(change=pl.col(\"count\").diff())\n",
    "#print( humpty_cum.keys() )\n",
    "#print( humpty_cum['2021-08-01'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7348f87-5c14-48b7-aa1e-315da18b3533",
   "metadata": {},
   "source": [
    "# Step 2: Code to create fair comparison for different forecast methods.  \n",
    "\n",
    "\n",
    "To compare Humpty to the published forecasts of other methods/models, some accommodation to the particulars of each method is needed.  Since methods offer various number of predictions at various times (including a periodic) there is no fair method to compare all at once.\n",
    "Rather we can perform a pairwise comparison of humpty vs each model since our humpty baseline (offering 28 days of prediction for each data point) is complete enough to match forecast predictions of any model's particular dates (so long as the dates are within the interval of collected data).\n",
    "\n",
    "This is done as a pairwise runoff, that is humpty vs method-X basis where method-X ranges over the data set collected from (CITE )\n",
    "\n",
    "In the comparison of humpty vs method-X we perform the following steps:\n",
    "1) Create a comparable set of predictions matching method-X directly.\n",
    "2) Calculate a _mse sequence_ for each method over the comparable prediction time points.\n",
    "3) Calculate a total mse score over the comparable prediction time points\n",
    "\n",
    "\n",
    "*Step 1, Comparable set of predictions:* For each date $d$ when method-X offers a forecast (future prediction) we record the date of forecast and the 'target-dates' $t_d = [ t_1, t_2, \\cdots, t_k ]$ for which method-X furnishes predictions.  We label the dates for which method-X offers predictions as:  $D = [ d_{1}, d_{2}, \\cdots, d_{M} ]$.  Note if multiple predictions are provided by method-X we filter the forecast (signal is {\\it confirmed incidence num}, quantile is 0.5) as the most relevant forecast for comparison.\n",
    "\n",
    "\n",
    "*Step 2, Calculate a  _mse sequence_:*\n",
    "For each date $d \\in D$, let target dates $t_d = [t_1, t_2, \\cdots, t_k ]$ be the time points at which method-X furnishes predictions using only data up to date $d$.  We do likewise, using data up to and including date $d$ but no further, the humpty model (fitted to data historical to and including date $d$) is then used to predict {\\it confirmed incidence num} at forward times $t_1, t_2, \\cdots, t_k $ matching predictions of model-X.   We label the forecast counts of method-X as $V_{d,1}, V_{d,2}, \\cdots, V_{d,k}$ and the forecast counts of Humpty as $W_{d,1}, W_{d,2}, \\cdots, W_{d,k}$.  Since our data set of {\\it confirmed incidence num} only includes data from 2020-01-22 up to 2023-03-09, we limit the comparisons to only include dates and target-dates within the the data collection interval $I = [\\text{2020-01-22}, \\text{2023-03-09}]$  We are able to derive Humpty forecasts for any $d \\in I \\cap D(X)$.  Further, we are able to compare Humpty forecasts with that of method-X so long as $\\left( d \\in I \\cap D(X) \\right) \\wedge \\left( \\bigwedge_{ t_j \\in t_d } t_j \\in I \\cap D(X) \\right)$.\n",
    "\n",
    "Letting $C_i$ be the confirmed incidence number for each $i \\in I$ be actual counts from data, letting $T = D(X) \\cup I$, we can calculate a {\\it forecasting-MSE} function for both method-X and Humpty as follows:\n",
    "$$\n",
    "\\text{MSE}_X : T \\rightarrow {\\Bbb R}: i \\rightarrow \\left( \\sum_{j \\in t_i} \\sqrt{ ( C_j - V_{i,j} )^2 }  \\right)\n",
    "$$\n",
    "while \n",
    "$$\n",
    "\\text{MSE}_{\\text{h}} : T \\rightarrow {\\Bbb R} : i \\rightarrow \\left( \\sum_{j \\in t_i} \\sqrt{ ( C_j - W_{i,j} )^2 }  \\right)\n",
    "$$\n",
    "Both functions are defined for $i \\in T = D(X) \\cup I $, the plot of which indicates the forecast accuracy as a function of date.\n",
    "\n",
    "\n",
    "*Step 3, Calculating and comparing total {\\it mse scores}:*\n",
    "Finally a view of all pairs method-X vs Humpty is provided by calculating the total forecast accuracy comparison point as:\n",
    "$$( x, y ) \\ \\ \\text{with} \\ \\ x = \\sum_{i \\in T} MSE_X( i ) \\ \\ \\text{and} \\ \\, y = \\sum_{i \\in T} MSE_h( i )\n",
    "$$\n",
    "These points are plotted in log-log scale below in figure \\ref{fig:humpvsothers}, Note that the line $x=y$ represents {\\it equal quality outcomes} for overall forecast error.  Points while points $x>y$ represent an outcomes where the forecast quality (measured as sum MSE) of Humpty out performs that of method-X.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70799909-bd86-4495-8ac9-deb472796f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_forecasters=competitors.filter( (pl.col( \"incidence_period\" ) == \"epiweek\" )).filter( (pl.col(\"signal\") == \"confirmed_incidence_num\" ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7bef6-4a80-43a6-835b-8b63233bca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_filter( df, forecaster, signal='confirmed_incidence_num', period='epiweek', quantile=0.5  ):\n",
    "    return df.filter( pl.col( \"forecaster\" ) == forecaster )\\\n",
    "             .filter( pl.col( \"signal\" ) == signal )\\\n",
    "             .filter( pl.col( 'incidence_period' ) == period )\\\n",
    "             .filter( pl.col( \"quantile\" ) == quantile )\n",
    "def retrieve_comp_req( df, forecaster, signal='confirmed_incidence_num', period='epiweek' ):\n",
    "    T= standard_filter(df,forecaster, signal, period );\n",
    "    return T.unique(subset=[ 'forecast_date' , 'target_end_date'], maintain_order=True)\\\n",
    "            .select( ['forecast_date', 'target_end_date' ])\\\n",
    "            .group_by( \"forecast_date\" )\\\n",
    "            .agg(pl.col(\"target_end_date\"))\\\n",
    "            .sort( by=\"forecast_date\")\n",
    "def create_forecast_compare_req( forecaster=\"COVIDhub-ensemble\", signal='confirmed_incidence_num' , period='epiweek' ):\n",
    "    H=retrieve_comp_req( competitors, forecaster, signal, period );\n",
    "    rv = [];\n",
    "    #rv1 = H[:,0].to_list()\n",
    "    #rv2 = H[:,2].to_list();\n",
    "    rv = H.map_rows( lambda t:  ( t[0] , sorted( t[1] )) )\n",
    "    return list(zip( rv[:,0], [x.to_list() for x in rv[:,1]]  )); \n",
    "    # used to create compute map files.\n",
    "    # return H.map_rows( lambda t: t[0] + \":\" + \",\".join( sorted( t[1] )) + f\":{period}\")[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd09ee-451c-48c8-8f83-a9ae3c0b9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_forecast_compare_req( 'Microsoft-DeepSTIA' );\n",
    "print(str(G[:5]).replace(\"),\", \"),\\n\") + \"\\n...\\n\" + str(G[-5:]).replace(\")\", \"),\\n\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e0f3e-a8f6-4952-ade5-a94a3299cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = []; \n",
    "COMPS = []\n",
    "for m in week_forecasters['forecaster'].unique().to_list():\n",
    "    X = create_forecast_compare_req( m );\n",
    "    a = len( X )\n",
    "    b = sum( [ len(x[1]) for x in X ] )\n",
    "    c = max( [ len(x[1]) for x in X ] )\n",
    "    rv.append( (b,a,c, m ));\n",
    "    if ( b > 80 ) :\n",
    "        COMPS.append(m );\n",
    "rv.sort();\n",
    "rv.reverse();\n",
    "for k in rv:\n",
    "    print( f\"{k[3]:<30}\\t{k[0]}\\t{k[1]}\\t{k[2]}\\t{'*' if k[3] in COMPS else ''}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e4564-971c-4e18-94fb-841eb8461bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_common_frame( cmethod , log=None):\n",
    "    if log == None:\n",
    "        log = io.StringIO(\"\")\n",
    "    def simplify_fcast( df , value=\"value\"):\n",
    "        return df.select( value = pl.col( value), forecast_date = pl.col( \"forecast_date\"), target_end_date = pl.col( \"target_end_date\") , forecaster=pl.col(  \"forecaster\" ) ) \n",
    "    #F1 = simplify_fcast(standard_filter( humpty_hope, \"HUMPTY-baseline\" ));\n",
    "\n",
    "    def build_humpty_fcast_atpoint(fdate , matching_targets ): \n",
    "        \"\"\" \n",
    "        reading from the link below it appears that the epiweek forecast will integrates the values over the epi-week\n",
    "        https://github.com/reichlab/covid19-forecast-hub/blob/master/data-processed/README.md#What-is-a-forecast \n",
    "        \"\"\"\n",
    "        fdx  = humpty[fdate] ;\n",
    "        fdx2 = humpty_cum[fdate] ;\n",
    "        chunk  = pl.concat( [ fdx.filter( pl.col( 'forecast_date' ) == fdate ).filter( pl.col( \"target_end_date\" ) == g ) for g in matching_targets], how=\"vertical\").sort( \"target_end_date\") \n",
    "        chunk2 = pl.concat( [fdx2.filter( pl.col( 'forecast_date' ) == fdate ).filter( pl.col( \"target_end_date\" ) == g ) for g in [ fdate ] + matching_targets], how=\"vertical\").sort( \"target_end_date\")        \n",
    "        chunk2 = chunk2.with_columns( change=pl.col( \"value\" ).diff() )\n",
    "        chunk2 = pl.concat( [ chunk2.filter( pl.col( \"target_end_date\" ) == g ) for g in matching_targets ] , how = \"vertical\" ).sort( \"target_end_date\" )\n",
    "        #chunk2 = chunk2.rename( {\"value\", \"oldvalue\"} ); #.rename( {\"change\", \"value\" })\n",
    "        #print( \">>\"  , chunk2  );\n",
    "        #chunk2.with_columns( pl.cols().add( )  )\n",
    "        return chunk2\n",
    "\n",
    "    def verify_humpty_fcast_match( fdate, matching_targets ):\n",
    "        cnt = 0; \n",
    "        try:\n",
    "            fdx = humpty[fdate] ;\n",
    "            chunk = pl.concat( [fdx.filter( pl.col( 'forecast_date' ) == fdate ).filter( pl.col( \"target_end_date\" ) == g ) for g in matching_targets], how=\"vertical\").sort( \"target_end_date\") \n",
    "            cnt = chunk.select(pl.len()).item()\n",
    "        except:\n",
    "            ...\n",
    "        return (cnt == len( matching_targets ))#et is the number of new daily h\n",
    "\n",
    "    def build_humpty_matching( cmethod , log=None):\n",
    "        status, comp = verify_humpty_matching( cmethod , log=log );\n",
    "        if len(comp):\n",
    "            return pl.concat( [ build_humpty_fcast_atpoint( fdate, targets ) for fdate, targets in comp ] , how=\"vertical\" )\n",
    "        else:\n",
    "            return None;\n",
    "    \n",
    "    def verify_humpty_matching( cmethod , log =None ):\n",
    "        comp = create_forecast_compare_req( forecaster=cmethod );\n",
    "        rv_comp_map = [];\n",
    "        rv = True;\n",
    "        for fdate, targets in comp:\n",
    "            if (len( targets ) != 4 ):\n",
    "                note = f\"problem at {fdate} {cmethod} forecast only includes {len(targets)} dates , so humpty is matching\" \n",
    "                if log:\n",
    "                    log.write( note + \"\\n\" ) \n",
    "                rv = False\n",
    "            if not verify_humpty_fcast_match( fdate, targets ) :\n",
    "                note = f\"problem with {fdate} {targets} humpty doesn't have coverage \" \n",
    "                if log: \n",
    "                    log.write( note + \"\\n\"  )\n",
    "                rv = False;\n",
    "            else:\n",
    "                rv_comp_map.append( (fdate, targets ));\n",
    "        return (rv, rv_comp_map )\n",
    "\n",
    "    F2 = simplify_fcast(standard_filter( competitors, cmethod ));\n",
    "    gocond, comp = verify_humpty_matching( cmethod , log = log );\n",
    "    if (len(comp)):\n",
    "        F1 = simplify_fcast(build_humpty_matching( cmethod , log = log ), value = \"change\" )\n",
    "        CU = pl.concat( [F1, F2], how=\"vertical\" ).sort(\"target_end_date\" );\n",
    "    else: \n",
    "        CU = F2\n",
    "\n",
    "\n",
    "    return (CU, cmethod, create_forecast_compare_req( forecaster=cmethod ), log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2b1eb-2391-4eaf-b498-0b0c2e33d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \" example:  create a comparison for forecasting \" )\n",
    "a,b,c,h = build_common_frame(  'Microsoft-DeepSTIA'  );\n",
    "print ( a  )\n",
    "h.seek(0)\n",
    "print ( h.read() ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e089b-7227-4047-a29b-1efb7fa9cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_side_by_side( cmethod, debug=False ):\n",
    "    CU, cmethod, comp_map, issues = build_common_frame( cmethod ); # creates a data frame with match up (as many as possible) \n",
    "    RU = list(CU.group_by([\"forecast_date\"] ));\n",
    "    RU.sort();\n",
    "    #print( \" RU \"*30 );\n",
    "    #print( RU )\n",
    "    ##\n",
    "    ## Delphi for example makes a prediction on forecast date for target_end_date which is 5 days out, with 3 subsequent forecasts at week intervals from first forecast.\n",
    "\n",
    "    def cmp_group( dx, actuals , comp_map ):\n",
    "        CM = dict( comp_map );\n",
    "        FD=dx[1]['forecast_date'].unique()[0]; \n",
    "        Methods = dx[1]['forecaster'].unique();\n",
    "        RV = {};\n",
    "        for e,k in enumerate( CM[FD]):\n",
    "            # k is the date of forecast\n",
    "            for m in Methods:\n",
    "                if m not in RV:\n",
    "                    RV[m]=[]\n",
    "                g = dx[1].filter( (pl.col('forecaster') == m )).filter( (pl.col( \"target_end_date\" ) == k))\n",
    "                dstep = g['target_end_date'][0]\n",
    "                # need to sum actual change from dstep to k.\n",
    "                \n",
    "                actuals_count_base = actuals_day.filter( (pl.col( \"date\" ) == (dstep if e==0 else CM[FD][e-1] ))).select( pl.col(\"count\"))[0,0]\n",
    "                actuals_count_next = actuals_day.filter( (pl.col( \"date\" ) == (dstep if e==0 else CM[FD][e] ))).select( pl.col(\"count\"))[0,0]                                    \n",
    "                #actuals = actuals_day.filter((pl.col(\"date\")==dstep)).select(pl.col(\"change\"))[0,0]\n",
    "                actuals = actuals_count_next - actuals_count_base;\n",
    "                disp = (g['value'][0] - actuals );\n",
    "                sdisp = pow( disp ,2);\n",
    "                #print( f\"@{FD} {m} forward:{k} or {dstep}, mse:{sdisp} \" )\n",
    "                RV[m].append( sdisp );\n",
    "        for m in RV:\n",
    "            RV[m] = pow( sum( RV[m]), 0.5);\n",
    "        RV['date'] = FD;\n",
    "        return RV\n",
    "          \n",
    "    DD =[ cmp_group( dx, actuals_day, comp_map ) for dx in RU if dx[1].shape[0] == 8 ]\n",
    "    reform = {'date':[d['date'] for d in DD], 'humpty':[d['HUMPTY-baseline'] for d in DD], cmethod: [d[cmethod] for d in DD]}\n",
    "\n",
    "    rf = pl.DataFrame( reform )\n",
    "    #print( rf )\n",
    "    return (rf, cmethod, DD, issues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359855f4-b249-4e69-9de2-96f7f7609079",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_side_by_side( \"PR_UMD-CF_RepTiLe\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38fed9-92d8-45b6-96ad-1346407438c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( actuals_day.filter( pl.col( \"date\" ) > '2021-01-01' ).filter( pl.col( \"date\" ) < '2021-02-01' ) )\n",
    "print( standard_filter(week_forecasters, forecaster=\"CovidAnalytics-DELPHI\" ).filter( pl.col( \"target_end_date\" ) > '2021-01-01' ).filter( pl.col( \"target_end_date\" ) < '2021-02-01' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a15a6a-5217-4a2c-93d9-49aa4dd1d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot( rf, FMETHOD , output=None): \n",
    "    x = rf.select(\"date\" )[:,0].to_list(); #np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)])\n",
    "    y = rf.select( \"humpty\" )[:,0].to_list(); #np.random.randint(100, size=x.shape)\n",
    "    y2 = rf.select( FMETHOD )[:,0].to_list();#np.random.randint( 100, size=x.shape);\n",
    "    plt.figure( figsize=(18,5))\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.plot(x, y, color='blue' , label='humpty')\n",
    "    plt.plot(x, y2, color='orange' , label=FMETHOD)\n",
    "    plt.legend();\n",
    "    plt.title( \"Forecast LSE\" )\n",
    "    if ( output == None ):\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig( output );\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3b589-c081-410c-b2e5-11232b76143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"example 2: Lets do a side by side for covidhum-ensemble, note issues with covidhub w/r/t expected 4 forecast points per date\" )\n",
    "rf, cm, DD, issues = create_side_by_side( \"COVIDhub-ensemble\" )\n",
    "compare_plot( rf, \"COVIDhub-ensemble\" )\n",
    "issues.seek(0)\n",
    "print( \"\\n\".join(issues.read().split(\"\\n\")) + \"...\" )\n",
    "print( rf )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e385b-b2ef-4395-8d52-c704fa3b34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( week_forecasters.filter( pl.col( \"forecast_date\" ) == \"2020-07-05\" ))\n",
    "\n",
    "#print( x1.filter( pl.col( \"forecast_date\" ) == \"2020-07-06\" ))\n",
    "#print( competitors.filter( pl.col( \"forecast_date\" ) == \"2020-07-06\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca723a8-b35e-47f7-ba9c-cf92909c8ba1",
   "metadata": {},
   "source": [
    "# COMPARING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb73a3d-e2d0-4fe6-a7fe-1339756d9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_comp_file = False;\n",
    "FXS = week_forecasters['forecaster'].unique().to_list()\n",
    "print( FXS )\n",
    "print(COMPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc84dc-3e37-441a-a528-dd5dccbc905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.style.use('ggplot') \n",
    "G1 = [\"AMM-EpiInvert\",\"BPagano-RtDriven\",\"CEID-Walk\",\"Covid19Sim-Simulator\",\"CovidActNow-SEIR_CAN\",\"CovidAnalytics-DELPHI\",\"COVIDhub-4_week_ensemble\",\"COVIDhub-baseline\",\"COVIDhub_CDC-ensemble\",\"COVIDhub-ensemble\",\"COVIDhub-trained_ensemble\",\"CU-select\",\"DDS-NBDS\",\"Google_Harvard-CPF\",\"IEM_MED-CovidProject\",\"IHME-CurveFit\",\"IowaStateLW-STEM\",\"IQVIA_ACOE-STAN\",\"IUPUI-HkPrMobiDyR\",\"JCB-PRM\",\"JHUAPL-Bucky\",\"JHUAPLTDWG-ICATTML\",\"JHU_CSSE-DECOM\",\"JHU_IDD-CovidSP\",\"JHU_UNC_GAS-StatMechPool\",\"Karlen-pypm\",\"KITmetricslab-select_ensemble\",\"LANL-GrowthRate\",\"LNQ-ens1\",\"LosAlamos_NAU-CModel_SDVaxVar\",\"LUcompUncertLab-VAR_3streams\",\"Microsoft-DeepSTIA\",\"MIT-Cassandra\",\"MIT_ISOLAT-Mixtures\",\"MOBS-GLEAM_COVID\",\"MUNI-ARIMA\",\"OliverWyman-Navigator\",\"OneQuietNight-ML\",\"PR_UMD-CF_RepTiLe\",\"RobertWalraven-ESG\",\"SDSC_ISG-TrendModel\",\"SigSci-TS\",\"UChicagoCHATTOPADHYAY-UnIT\",\"UCLA-SuEIR\",\"UCSB-ACTS\",\"UMich-RidgeTfReg\",\"USACE-ERDC_SEIR\",\"USC-SI_kJalpha\",\"UVA-Ensemble\"]\n",
    "G2 = [\"BPagano-RtDriven\",\"CEID-Walk\",\"CovidAnalytics-DELPHI\",\"COVIDhub-4_week_ensemble\",\"COVIDhub-baseline\",\"COVIDhub_CDC-ensemble\",\"COVIDhub-ensemble\",\"COVIDhub-trained_ensemble\",\"CU-select\",\"IEM_MED-CovidProject\",\"JHUAPL-Bucky\",\"JHU_CSSE-DECOM\",\"JHU_IDD-CovidSP\",\"Karlen-pypm\",\"KITmetricslab-select_ensemble\",\"LANL-GrowthRate\",\"Microsoft-DeepSTIA\",\"MIT-Cassandra\",\"MIT_ISOLAT-Mixtures\",\"MUNI-ARIMA\",\"RobertWalraven-ESG\",\"UCLA-SuEIR\",\"UMich-RidgeTfReg\",\"USC-SI_kJalpha\",\"UVA-Ensemble\",\"BPagano-RtDriven\",\"CEID-Walk\",\"CovidAnalytics-DELPHI\",\"COVIDhub-4_week_ensemble\",\"COVIDhub-baseline\",\"COVIDhub_CDC-ensemble\",\"COVIDhub-ensemble\",\"COVIDhub-trained_ensemble\",\"CU-select\",\"IEM_MED-CovidProject\",\"JHUAPL-Bucky\",\"JHU_CSSE-DECOM\",\"JHU_IDD-CovidSP\",\"Karlen-pypm\",\"KITmetricslab-select_ensemble\",\"LANL-GrowthRate\",\"Microsoft-DeepSTIA\",\"MIT-Cassandra\",\"MIT_ISOLAT-Mixtures\",\"MUNI-ARIMA\",\"RobertWalraven-ESG\",\"UCLA-SuEIR\",\"UMich-RidgeTfReg\",\"USC-SI_kJalpha\",\"UVA-Ensemble\"]\n",
    "G3 = G1 ; # FXS\n",
    "G4 = COMPS;\n",
    "TAB = [];\n",
    "IMAGES=True;\n",
    "for g in G4:\n",
    "    output = f\"humpty_vs_{g}.png\" \n",
    "    output_log = f\"humpty_vsw_{g}log.txt\"\n",
    "    print( f\" {g} -> {output}\" );\n",
    "    rf,cmethod, DD, issues = create_side_by_side( g );\n",
    "    issues.seek(0);\n",
    "    if IMAGES:\n",
    "        compare_plot( rf, cmethod, output=output ) \n",
    "    try:\n",
    "        MSETHUMP = rf.select(pl.sum( \"humpty\" ));\n",
    "        MSETCOMP = rf.select( pl.sum( cmethod ));\n",
    "        TAB.append( (MSETHUMP[0,0], MSETCOMP[0,0], f\"{cmethod} \" ))\n",
    "    except:\n",
    "        print( f\"{cmethod} has no comparison for humpty: its MSE is {MSETCOMP}\" );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4315db-b0f4-48e9-af02-262de32d87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "x = [math.log( t[1] ) for t in TAB]\n",
    "y = [math.log( t[0] ) for t in TAB]\n",
    "l = [t[2] for t in TAB]\n",
    "plt.figure( figsize=(10,10))\n",
    "plt.scatter( x, y,  color=\"blue\" )\n",
    "plt.plot( [13.5, 17.], [13.5, 17.], \"orange\")\n",
    "plt.annotate( \"total forecast mse accuracy neutral to Humpty\" , (13.50 +0.2 - 0.12, 13.50 + 0.02 + 0.16 ), rotation=48.5 )\n",
    "plt.annotate( \"Humpty improves upon methods in region x > y \" , (13.50 + 0.2 , 13.50 -0.04 + 0.16 ), rotation=48.5 )\n",
    "for i, txt in enumerate(l):\n",
    "    b1 = 0.0\n",
    "    b0 = 0.0\n",
    "    adjust = { \"LosAlamos\":(-1.4,0), \"STEM\":(0,0), \"Simulator\":(-0.9,0.01),  \"LNQ\":(-0.5,-0.03), \"UMich\":(0.03, -0.10),\n",
    "              \"LANL\":(-0.8,0), \"UCLA\":(0.05,-0.05), \"4_week\":(-1.2,0), \"ESG\" :(0.0,0.0), \"CEID\":(0.05,0),\n",
    "                \"Bucky\":(0.05,0.01), \"Microsoft\":(-0.9,-0.02), \"IDD\":(0,0), \"COVIDhub-baseline\":(-.8,0.02),\n",
    "                \"MED\":(0,-.04),\"ISOLAT\":(0,0), \"Cassandra\":(0,0), \"KITmetrics\":(0,0), \"CDC-ensemble\":(-1.1,0 ),\n",
    "                \"DELPH\":(-.9,0.02), \"UVA\":(0,-0.06), \"COVIDhub-trained\":(-1.2,-0.04), \"USC\":(0,0), \"COVIDhub-ensemble\":(-0.9,-0.025),\n",
    "                \"Driven\":(0,0), \"CU-select\":(-0.4,0.01),  \"PR_UMD\":(-.6,0), \"LUcomp\" :(-1.34,0), \"Iowa\":(-0.8,-0.08),\n",
    "                 \"Karlen\":(0.05, -0.02), \"MED\":(0.05, -0.06), \"ISOLAT\":(0.05,-0.04), \"MOBS\":(0.05,0), \"DDS\":(0.05,0), \n",
    "                \"JHU_UNC\":(0.05,0),\"HME\":(0.05,0), \"JHU_CSS\":(0.05,0), \"IDD\": (-0.7,0), \"Driven\":(-0.8,-0.03), \n",
    "                \"USC\":(0.05,-0.03),\"raven\":(0.03,0.02), \"KIT\":(0.04,0.03), \"Cass\":(0.03, -0.05)}\n",
    "    arg = 0;\n",
    "    for k in adjust: \n",
    "        if k in txt:\n",
    "            b0, b1 = adjust[k]\n",
    "    plt.annotate(txt, (x[i] + b0, y[i] + b1), rotation=arg )\n",
    "#plt.scatter(x, y, s=area2, marker='o', c=c)\n",
    "# Show the boundary between the regions:\n",
    "#plt.scatter(x, y, s=area2, marker='o', c=c)\n",
    "# Show the boundary between the regions:\n",
    "#theta = np.arange(0, np.pi / 2, 0.01)\n",
    "#plt.plot(r0 * np.cos(theta), r0 * np.sin(theta))\n",
    "plt.xlabel( \"log total mse error (point labeled method)\" )\n",
    "plt.ylabel( \"log total mse error (humpty)\" )\n",
    "plt.title( \"MSE four week forecast accuracy\" )\n",
    "plt.savefig( \"Humpty_vs_comps.png\" )\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41787e-8e58-4a98-9000-fac732a9b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "FXS = week_forecasters['forecaster'].unique().to_list()\n",
    "FXS.sort()\n",
    "all_dates = competitors.filter( pl.col( \"incidence_period\") == \"epiweek\").select( pl.col( \"forecast_date\" )).unique().sort(by=\"forecast_date\")[:,0].to_list();                     \n",
    "all_dates = week_forecasters.filter( pl.col( \"incidence_period\") == \"epiweek\").select( pl.col( \"forecast_date\" )).unique().sort(by=\"forecast_date\")[:,0].to_list();                     \n",
    "\n",
    "plt.figure( figsize=(64,5) );\n",
    "c = 0; \n",
    "plt.plot( all_dates, [ 0 for g in all_dates ] , \".\" ,  color='k'); \n",
    "for mods in FXS:\n",
    "    temp = standard_filter( week_forecasters , mods )\n",
    "    d2 = temp.select( pl.col( \"forecast_date\" )).unique().sort(by=\"forecast_date\")[:,0].to_list() ;\n",
    "    plt.plot( [d for d in d2] , [ 1000.0 - (20*c/1.0) for d in d2 ], \"x\", label=mods );\n",
    "    plt.annotate( f\"{mods}\" , (\"2020-04-06\" if (c %2 == 0 ) else \"2020-07-17\", 1000.0 - (20*c) ), size=10) #, rotation=0,0 )\n",
    "    c += 1;    \n",
    "#.filter( pl.col( \"incidence_period\" ) == \"epiweek\").filter( pl.col( \"signal\" ) == select( \"forecaster) \n",
    "#plt.plot( all_dates , label=\"all\")\n",
    "#plt.plot( all_dates, [ 1.0 if d in dates_for_delphi else 0.0 for d in all_dates ] , 'bo', label=\"delphi\");\n",
    "#plt.plot(  all_dates, [ 0.9 if d in dates_for_arima else 0.0 for d in all_dates ], 'r+', label =\"arima\" );\n",
    "plt.xticks( rotation=90 , ha=\"right\")\n",
    "plt.title( \"method coverage\" )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ccf55-e224-49ba-855f-50d256671081",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in FXS: \n",
    "     color='k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad05d9-0665-4bc3-b6db-8a9f4ec8f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( competitors.columns )\n",
    "print( competitors.select('incidence_period').unique(  ))\n",
    "print( competitors.select('signal').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ecf3e-897f-4df8-a7d4-47f4ca4c61c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
